{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "babceb77",
   "metadata": {},
   "source": [
    "# TP : Analyse en Composantes Principales (ACP) et choix du clustering\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "### üåü Objectifs du TP\n",
    "- Comprendre le fonctionnement du PCA (ACP en fran√ßais)\n",
    "- R√©duire la dimension de donn√©es pour les visualiser\n",
    "- Comparer les r√©sultats de clustering (K-Means et DBSCAN) sur les donn√©es projet√©es\n",
    "\n",
    "### üîç Qu'est-ce que le PCA ?\n",
    "L'**Analyse en Composantes Principales** (ACP ou PCA pour *Principal Component Analysis*) est une m√©thode math√©matique qui permet de :\n",
    "- **R√©duire le nombre de dimensions** d'un jeu de donn√©es,\n",
    "- En conservant un maximum d'information (**variance**),\n",
    "- En projetant les points dans un nouvel espace (appel√© espace des composantes principales).\n",
    "\n",
    "Cela permet notamment de **visualiser** des donn√©es complexes en 2D, ou de **pr√©traiter les donn√©es** avant un clustering.\n",
    "\n",
    "### üßπ Pourquoi pr√©traiter les donn√©es avec le PCA avant un clustering ?\n",
    "- Lorsque les donn√©es ont **beaucoup de dimensions**, certaines peuvent √™tre **corr√©l√©es ou peu informatives**.\n",
    "- Le PCA √©limine ces redondances et simplifie la structure des donn√©es.\n",
    "- En r√©duisant le bruit et la complexit√©, cela peut :\n",
    "  - am√©liorer la qualit√© des clusters,\n",
    "  - faciliter le travail de K-Means ou DBSCAN,\n",
    "  - r√©duire les temps de calcul.\n",
    "\n",
    "En r√©sum√©, le PCA sert souvent de **filtre intelligent** avant de lancer un algorithme de regroupement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae372f3",
   "metadata": {},
   "source": [
    "## 2. Test avec un jeu de donn√©es multidimensionnel\n",
    "\n",
    "Jusqu'ici, on n'a travaill√© qu'avec des donn√©es ne comportant que deux dimensions pour une meilleure visibilit√©. Qu'en est-il des donn√©es mutidimensionnelles ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d90d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation des biblioth√®ques\n",
    "!pip install pandas numpy scikit-learn matplotlib seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be15f070",
   "metadata": {},
   "source": [
    "### üìÅ 2.1 G√©n√©ration de donn√©es (5 dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787d4a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cr√©ation d'un jeu avec 5 caract√©ristiques\n",
    "X, y = make_classification(n_samples=300, n_features=5, n_redundant=0, \n",
    "                           n_clusters_per_class=1, random_state=42)\n",
    "\n",
    "# Conversion en DataFrame\n",
    "df = pd.DataFrame(X, columns=[f\"Feature_{i+1}\" for i in range(X.shape[1])])\n",
    "df.head()  # Affichage des attributs et des 5 premiers enregistrements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f441cb",
   "metadata": {},
   "source": [
    "### üîå2.2  D√©termination des composantes et variance par l'algorithme PCA \n",
    "\n",
    "L'algorithme PCA va permettre de diminuer le nombre de dimensions, de 5 √† 2 ici."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76997af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# R√©duction √† 2 composantes principales\n",
    "pca = PCA(n_components=2)\n",
    "X_reduit = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717f2745",
   "metadata": {},
   "source": [
    "Chaque **composante** est une combinaison lin√©aire de plusieurs crit√®res, et c‚Äôest cette combinaison enti√®re qui explique une part de la variance.\n",
    "\n",
    "**La variance** :\n",
    "\n",
    "- ‚ùå La variance expliqu√©e par une composante ne refl√®te pas directement le poids d‚Äôun crit√®re (ou variable).\n",
    "- ‚úÖ Le pourcentage de variation totale des donn√©es capt√© par chaque **composante principale**.\n",
    "\n",
    "\n",
    "\n",
    "üéì **<u>Exemple</u>** :\n",
    "Si `Composante 1` explique 60% de la variance, cela signifie qu‚Äôen projetant toutes les donn√©es sur cet axe, on conserve 60 % de l'information globale. Mais cela ne dit pas quel crit√®re (ex : revenu, √¢ge...) est responsable de ce 60 %.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23600ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©termination de la variance de chaque composante \n",
    "pca = PCA(n_components=2)  # 2 composantes\n",
    "X_reduit = pca.fit_transform(X)\n",
    "print(pca.explained_variance_ratio_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254a7f22",
   "metadata": {},
   "source": [
    "On voit que seulement **55% (32% + 23%) de l'information** est conserv√©e : il va falloir utiliser plus de composants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b4e8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©termination de la variance de chaque composante \n",
    "pca = PCA(n_components=3) # 3 composantes\n",
    "X_pca3 = pca.fit_transform(X)\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b755cd11",
   "metadata": {},
   "source": [
    "On passe maintenant √† **75% de l'information** de conserv√©e : c'est bien mieux :).\n",
    "Pour visualiser tout cela, on va afficher un **graphique par paire de composants**, ce sera plus lisible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6adbf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# R√©duction √† 3 composantes principales\n",
    "pca = PCA(n_components=3)\n",
    "X_pca3 = pca.fit_transform(X)\n",
    "\n",
    "\n",
    "# Affichage des 3 combinaisons de composantes principales\n",
    "pairs = [(0, 1), (0, 2), (1, 2)]\n",
    "for i, j in pairs:\n",
    "    plt.figure()\n",
    "    plt.scatter(X_pca3[:, i], X_pca3[:, j], s=50)\n",
    "    plt.xlabel(f\"Composante {i+1}\")\n",
    "    plt.ylabel(f\"Composante {j+1}\")\n",
    "    plt.title(f\"Projection : Composantes {i+1} et {j+1}\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a359b665",
   "metadata": {},
   "source": [
    "### üìä 2.3 Comparaison avec K-Means / DBSCAN\n",
    "\n",
    "**<u>Remarque</u>** : on pourra toujours appliquer la `m√©thode du coude (K-Means)` et le `k-distance-plot (DBSCAN)` pour d√©terminer les **meilleurs param√®tres** (n_cluster et eps / min_samples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1cf56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "### üîé Application de K-Means \n",
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)  # Meilleur k observ√©\n",
    "k_labels = kmeans.fit_predict(X_pca3)\n",
    "\n",
    "# Affichage 2D selon les 2 premi√®res composantes\n",
    "plt.scatter(X_pca3[:, 0], X_pca3[:, 1], c=k_labels, cmap=\"viridis\", s=50)\n",
    "plt.title(\"K-Means sur donn√©es PCA (3 composantes)\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "### üîé DBSCAN\n",
    "dbscan = DBSCAN(eps=0.813, min_samples=3)  # Meilleure estimation eps/min_samples\n",
    "d_labels = dbscan.fit_predict(X_pca3)\n",
    "\n",
    "# Affichage 2D selon les 2 premi√®res composantes\n",
    "plt.scatter(X_pca3[:, 0], X_pca3[:, 1], c=d_labels, cmap=\"plasma\", s=50)\n",
    "plt.title(\"DBSCAN sur donn√©es PCA (3 composantes)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e877f3f9",
   "metadata": {},
   "source": [
    "**<u>Remarque</u>** : on peut aussi proposer un **affichage en 3D** √† titre informatif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b51cde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### üßä Affichage 3D avec matplotlib\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(X_pca3[:, 0], X_pca3[:, 1], X_pca3[:, 2], c=k_labels, cmap='viridis', s=50)\n",
    "ax.set_xlabel(\"Composante 1\")\n",
    "ax.set_ylabel(\"Composante 2\")\n",
    "ax.set_zlabel(\"Composante 3\")\n",
    "ax.set_title(\"Visualisation 3D des donn√©es PCA + K-Means\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bc6878",
   "metadata": {},
   "source": [
    "### üéØ2.4. Comparaison / Questions\n",
    "\n",
    "- Qu'observe-t-on ? *On observe que les donn√©es projet√©es en 2D conservent une structure qui permet de distinguer plusieurs groupes.\n",
    "  Les points forment des regroupements visibles, bien que la s√©paration ne soit pas toujours nette.*\n",
    "  \n",
    "  \n",
    "- Le **clustering** change-t-il entre K-Means et DBSCAN ? *Oui. K-Means impose un nombre fixe de clusters et d√©coupe l'espace de fa√ßon circulaire. DBSCAN, lui, d√©tecte automatiquement les groupes selon la densit√© des points et peut identifier du bruit.*\n",
    "\n",
    "\n",
    "- Quels sont les **avantages / inconv√©nients** visibles ? *K-Means d√©termine efficacement 3 clusters (on pourrait essayer avec d'autres valeurs). DBSCAN n'est pas fiable ici, les donn√©es ne sont pas assez denses et/ou trop espac√©es.*\n",
    "\n",
    "\n",
    "- Que nous apprend la projection PCA sur la forme des donn√©es ? *Elle montre que les donn√©es initiales √† 5 dimensions peuvent √™tre bien repr√©sent√©es dans un espace ici √† 3 dimensions tout en conservant une bonne partie de la structure. Cela facilite la visualisation et le clustering.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a345a39",
   "metadata": {},
   "source": [
    "## 3. TP : Cat√©goriser des patients selon le risque de cancer.\n",
    "\n",
    "\n",
    "## üéØ Objectifs du TP\n",
    "- Analyser un jeu de donn√©es contenant des informations sur des **facteurs de risque de cancer**.\n",
    "- R√©duire la dimension des donn√©es √† 2 ou 3 composantes avec PCA.\n",
    "- Visualiser les individus dans l'espace r√©duit.\n",
    "- Explorer les regroupements potentiels par clustering (`K-Means` ou `DBSPAN`).\n",
    "\n",
    "Un fichier de donn√©es contient 2000 clients fictifs avec les informations suivantes :\n",
    "- `√¢ge` (en ann√©es)\n",
    "- `poids` (en kg)\n",
    "- `ant√©c√©dents familiaux` (oui / non)\n",
    "- `tabac` (oui / non)\n",
    "- `alcool` (oui / non)\n",
    "- `activit√© sportive`(faible, moyenne, intense)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6deee2a",
   "metadata": {},
   "source": [
    "### üì• 3.1 ‚Äì Chargement des donn√©es avec pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651245ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement depuis un fichier CSV (√† placer dans le m√™me dossier que ce notebook)\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"donnees_cancer_pca.csv\", encoding=\"utf-8\", encoding_errors=\"ignore\")  # Noter le UTF-8 :)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfed0ac6",
   "metadata": {},
   "source": [
    "### üîÑ 3.2 ‚Äì Encodage des donn√©es\n",
    "\n",
    "Avant d'appliquer le PCA, il faut convertir les variables non num√©riques en format num√©rique. On utilise :\n",
    "\n",
    "- `LabelEncoder` pour les **variables ordinales**, c'est-√†-dire celles qui ont un ordre logique entre les modalit√©s (ex : \"Faible\" < \"Mod√©r√©e\" < \"Intense\").\n",
    "- `get_dummies` pour les **variables nominales**, qui repr√©sentent des cat√©gories sans ordre (ex : \"Oui\" ou \"Non\").\n",
    "\n",
    "\n",
    "**<u>Remarques</u>** :\n",
    "- On pourrait utiliser tout le temps `LabelEncoder` m√™me √† la place de `get_dummies`, attention √† ne pas introduire **d'ordre artificiel**.\n",
    "- `get_dummies` permet d'encoder plusieurs attributs en m√™me temps contrairement √† `LabelEncoder`.\n",
    "\n",
    "\n",
    "#### üß† **Fonctionnement** de `get_dummies` \n",
    "\n",
    "Quand `get_dummies` encode une variable binaire comme \"*Fumeur*\" avec les modalit√©s \"*Oui*\" et \"*Non*\", il cr√©e deux colonnes :\n",
    "\n",
    "| Fumeur_Oui | Fumeur_Non |\n",
    "|------------|------------|\n",
    "| 1          | 0          |\n",
    "| 0          | 1          |\n",
    "\n",
    "Avec `drop_first=True`, seule la colonne `Fumeur_Oui` est conserv√©e. Cela √©vite les **redondances** et les **liens entre attributs** qui pourraient perturber des algorithmes contre les r√©gressions et le PPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833a40e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# On cr√©e une copie de df pour travailler dessus sans modifier l'original\n",
    "# Cela √©vite d'alt√©rer le DataFrame de base si on veut le r√©utiliser ensuite \n",
    "# (l'encodage rajoute des colonnes et modifie les valeurs).\n",
    "X = df.copy()\n",
    "\n",
    "\n",
    "# Encodage de l'activit√© physique (ordinale)\n",
    "le = LabelEncoder()\n",
    "X[\"Activit√©_Physique\"] = le.fit_transform(X[\"Activit√©_Physique\"])\n",
    "\n",
    "# Encodage one-hot des autres variables cat√©gorielles (non ordonn√©es)\n",
    "# Le drop_first = True permet d'√©viter les redondances \n",
    "X_encoded = pd.get_dummies(X, columns=[\"Fumeur\", \"Consommation_Alcool\", \"Ant√©c√©dents_Familiaux\"], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2292589",
   "metadata": {},
   "source": [
    "### üß† 3.4  Analyse en composantes principales (PCA)\n",
    "\n",
    "Il faut d√©terminer le nombre de composantes optimal pour le PCA. Mais avant cela, il faut **standardiser** les crit√®res, c'est √† dire leur donner un **poids √©gal** (les composantes sont des combinaisons lin√©aires des crit√®res fournis, ainsi, un √¢ge entre 40 et 70 ans p√®serait bien plus qu'un 0 / 1 caract√©risant un fumeur ou non).\n",
    "\n",
    "‚úÖ Ce que fait `StandardScaler` :\n",
    "Il transforme chaque colonne pour qu‚Äôelle ait :\n",
    "- une moyenne = 0\n",
    "- un √©cart type = 1\n",
    "\n",
    "Autrement dit, il met toutes **les variables sur la m√™me √©chelle**, ce qui rend leur importance √©quivalente dans le PCA.\n",
    "\n",
    "‚úÖ Nombre de **composantes n√©cessaires** au PCA : un minimum de **75% d'informations retenues** est attendu ici."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d12a2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mise des variables √† la m√™me √©chelle\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_encoded) # Entra√Ænement du scaler\n",
    "\n",
    "\n",
    "# TEST : PCA avec 2 composantes (avec r√©sultats)\n",
    "################### A COMPLETER ########################\n",
    "\n",
    "\n",
    "\n",
    "# TEST : PCA avec 3 composantes (avec r√©sultats)\n",
    "################### A COMPLETER ########################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19021d48",
   "metadata": {},
   "source": [
    "### üìåQuestions\n",
    "\n",
    "- 1. **Compl√©ter** le code manquant permettant de tester le PCA pour 2 et 3 composantes. On notera **<u>obligatoirement</u>** `X_pca` les donn√©es travaill√©es apr√®s l'entra√Ænement du mod√®le PCA.\n",
    "- 2. **Conclure** sur le nombre de composantes.\n",
    "\n",
    "**<u>Aide</u>** : on verra ici que *2 composantes* sont largement suffisantes (95% d'informations retenues)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463362ea",
   "metadata": {},
   "source": [
    "### üß† 3.5  Application du PCA et d√©termination du meilleur mod√®le K-Means / DBSCAN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c573cb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application de la PCA avec le bon nombre de composantes\n",
    "################### A COMPLETER ########################\n",
    "\n",
    "\n",
    "# Affichage 2D \n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], s=50, alpha=0.7)\n",
    "plt.xlabel(\"Composante 1\")\n",
    "plt.ylabel(\"Composante 2\")\n",
    "plt.title(\"Projection PCA (2 composantes)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdee9d6",
   "metadata": {},
   "source": [
    "### üìåQuestions\n",
    "\n",
    "- 1. **Compl√©ter** le code manquant.\n",
    "- 2. Quel mod√®le entre le **K-Means** et le **DBSCAN** pourrait-on appliquer ici ? Justifier. <u>ON FERA UNE ANALYSE SEULEMENT QUALITATIVE</u> (pas de tests). \n",
    "- 3. En d√©duire <u>qualitativement</u> le (ou les) param√®tres `n_clusters` (K_Means) ou `min_samples` / `eps` (DBSCAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378cf68a",
   "metadata": {},
   "source": [
    "### üß† 3.6  Application du PCA et d√©termination du meilleur mod√®le entre K-Means et DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f4ea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application du meilleur mod√®le avec les bons crit√®res\n",
    "################ A COMPLETER ###################\n",
    "\n",
    "\n",
    "# Affichage des r√©sultat\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=k_labels, cmap='Set2', s=50)\n",
    "\n",
    "# Ajouter les num√©ros de clusters en annotation au centre de chaque groupe\n",
    "for cluster_id in np.unique(k_labels):\n",
    "    # coordonn√©es du centre de gravit√© du cluster\n",
    "    x_mean = X_pca[k_labels == cluster_id, 0].mean()\n",
    "    y_mean = X_pca[k_labels == cluster_id, 1].mean()\n",
    "    plt.text(x_mean, y_mean, str(cluster_id), fontsize=14, weight='bold',\n",
    "             ha='center', va='center', color='black', bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.3'))\n",
    "\n",
    "plt.title(\"Algorithme sur donn√©es PCA avec num√©ros de clusters\")\n",
    "plt.xlabel(\"Composante 1\")\n",
    "plt.ylabel(\"Composante 2\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d109c104",
   "metadata": {},
   "source": [
    "### üìåQuestion\n",
    "\n",
    "A priori, combien de **groupes de patients** peut-on proposer √† partir des r√©sultats ?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6092ccea",
   "metadata": {},
   "source": [
    "### üß† 3.7  Pr√©diction de l'appartenance d'un patient √† une cat√©gorie \n",
    "\n",
    "On a vu qu'avec l'algorithme **DBSCAN**, on devait utiliser **KNN** pour **estimer la cat√©gorie d'appartenance** d'une nouvelle donn√©e. \n",
    "Voici la d√©marche √† suivre avec l'algorithme **K_Means**.\n",
    "\n",
    "#### üìù R√©sum√© des √©tapes de pr√©diction pour un nouveau patient\n",
    "\n",
    "| √âtape | Description |\n",
    "|-------|-------------|\n",
    "| 1Ô∏è‚É£ Encodage de l'activit√© physique | Utiliser le `LabelEncoder` d√©j√† entra√Æn√© (`le`) sur la colonne `\"Activit√©_Physique\"` |\n",
    "| 2Ô∏è‚É£ Encodage des variables nominales | Utiliser `pd.get_dummies` avec `drop_first=True` pour les variables comme `\"Fumeur\"`, `\"Alcool\"`... |\n",
    "| 3Ô∏è‚É£ Ajustement des colonnes | Ajouter les colonnes manquantes pour correspondre √† `X_encoded`, puis r√©ordonner les colonnes |\n",
    "| 4Ô∏è‚É£ Standardisation | Appliquer le `scaler.transform(...)` entra√Æn√© pr√©c√©demment sur `X_encoded` |\n",
    "| 5Ô∏è‚É£ R√©duction de dimension | Appliquer `pca.transform(...)` sur les donn√©es standardis√©es du patient |\n",
    "| 6Ô∏è‚É£ Pr√©diction du cluster | Utiliser `kmeans.predict(...)` pour obtenir le num√©ro du cluster associ√© |\n",
    "\n",
    "\n",
    "**<u>Exemple</u>** : On teste ici pour un patient avec ces caract√©ristiques : *√Çge = 65 ans, Poids = 80 kg, Ant√©c√©dents = Oui, Tabac = Non, Alcool = Oui, Activit√© = Faible*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc28486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caract√©ristiques du patient :\n",
    "# √Çge = 65 ans, Poids = 80 kg, Ant√©c√©dents = Oui, Tabac = Non, Alcool = Oui, Activit√© = Faible\n",
    "\n",
    "patient = pd.DataFrame([{\n",
    "    \"√Çge\": 65,\n",
    "    \"Poids\": 80,\n",
    "    \"Fumeur\": \"Non\",\n",
    "    \"Consommation_Alcool\": \"Oui\",\n",
    "    \"Ant√©c√©dents_Familiaux\": \"Oui\",\n",
    "    \"Activit√©_Physique\": \"Faible\"\n",
    "}])\n",
    "\n",
    "# √âtape 1 : Encodage de l'activit√© physique avec le m√™me LabelEncoder que pr√©c√©demment\n",
    "patient[\"Activit√©_Physique\"] = le.transform(patient[\"Activit√©_Physique\"])\n",
    "\n",
    "# √âtape 2 : Encodage one-hot des autres variables cat√©gorielles (comme dans le TP)\n",
    "patient_encoded = pd.get_dummies(patient, drop_first=True)\n",
    "\n",
    "# √âtape 3 : Ajouter les colonnes manquantes pour correspondre √† X_encoded\n",
    "for col in X_encoded.columns:\n",
    "    if col not in patient_encoded.columns:\n",
    "        patient_encoded[col] = 0\n",
    "patient_encoded = patient_encoded[X_encoded.columns]  # Reordonner les colonnes\n",
    "\n",
    "# √âtape 4 : Standardiser avec le scaler d√©j√† entra√Æn√©\n",
    "patient_scaled = scaler.transform(patient_encoded)\n",
    "\n",
    "# √âtape 5 : R√©duction avec le PCA d√©j√† entra√Æn√©\n",
    "patient_pca = pca.transform(patient_scaled)\n",
    "\n",
    "# √âtape 6 : Pr√©diction avec le mod√®le KMeans\n",
    "cluster_pred = kmeans.predict(patient_pca)[0]\n",
    "print(f\"‚úÖ Le patient est class√© dans le cluster {cluster_pred}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70fe8cb",
   "metadata": {},
   "source": [
    "### üß† 3.7  Analyse des r√©sultats\n",
    "\n",
    "Il est important de comprendre qu'avec le PCA, les **composantes** sont une **combinaison lin√©aires des crit√®res** relev√©s : on ne peut donc pas analyser directement les groupes obtenus.\n",
    "\n",
    "En revanche, on peut cibler les types de personnes composants les clusters : dans l'exemple ci-dessus, \n",
    "chaque cluster correspond probablement √† un **profil de risque** :\n",
    "  - üü© Un cluster peut regrouper des patients **jeunes, actifs, non-fumeurs, sans ant√©c√©dents** ‚Üí risque faible\n",
    "  - üü• Un autre cluster peut repr√©senter des patients **plus √¢g√©s, fumeurs, avec ant√©c√©dents** ‚Üí risque √©lev√©\n",
    "  - üü¶ Le troisi√®me est un **profil interm√©diaire** entre les deux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc61de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Ajout des labels K-Means aux donn√©es d'origine\n",
    "X_labeled = df.copy()\n",
    "X_labeled[\"Cluster\"] = k_labels\n",
    "\n",
    "\n",
    "# Projection 2D (composantes 1 et 2)\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], s=50, alpha=0.7)\n",
    "plt.xlabel(\"Composante 1\")\n",
    "plt.ylabel(\"Composante 2\")\n",
    "plt.title(\"Projection PCA (2 composantes)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Barplot de la consommation de tabac par cluster\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(\n",
    "    data=X_labeled.groupby(\"Cluster\")[\"Fumeur\"].apply(lambda x: (x == \"Oui\").mean()).reset_index(),\n",
    "    x=\"Cluster\", y=\"Fumeur\"\n",
    ")\n",
    "plt.title(\"Proportion de fumeurs par cluster\")\n",
    "plt.ylabel(\"Proportion de fumeurs\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Barplot de la consommation d'alcool par cluster\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(\n",
    "    data=X_labeled.groupby(\"Cluster\")[\"Consommation_Alcool\"].apply(lambda x: (x == \"Oui\").mean()).reset_index(),\n",
    "    x=\"Cluster\", y=\"Consommation_Alcool\"\n",
    ")\n",
    "plt.title(\"Proportion de consommateurs d'alcool par cluster\")\n",
    "plt.ylabel(\"Proportion d'alcool\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Barplot des ant√©c√©dents familiaux par cluster\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(\n",
    "    data=X_labeled.groupby(\"Cluster\")[\"Ant√©c√©dents_Familiaux\"].apply(lambda x: (x == \"Oui\").mean()).reset_index(),\n",
    "    x=\"Cluster\", y=\"Ant√©c√©dents_Familiaux\"\n",
    ")\n",
    "plt.title(\"Proportion d'ant√©c√©dents familiaux par cluster\")\n",
    "plt.ylabel(\"Proportion avec ant√©c√©dents\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Barplot de l'activit√© physique par cluster\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(\n",
    "    data=X_labeled.groupby(\"Cluster\")[\"Activit√©_Physique\"].value_counts(normalize=True).rename(\"Proportion\").reset_index(),\n",
    "    x=\"Cluster\", y=\"Proportion\", hue=\"Activit√©_Physique\"\n",
    ")\n",
    "plt.title(\"R√©partition de l'activit√© physique par cluster\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Boxplot de l'√¢ge par cluster\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.boxplot(data=X_labeled, x=\"Cluster\", y=\"√Çge\")\n",
    "plt.title(\"Distribution de l'√¢ge par cluster\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Boxplot du poids par cluster\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.boxplot(data=X_labeled, x=\"Cluster\", y=\"Poids\")\n",
    "plt.title(\"Distribution du poids par cluster\")\n",
    "plt.ylabel(\"Poids (kg)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7638dc16",
   "metadata": {},
   "source": [
    "### üß† R√©sum√© : interpr√©tation des clusters avec les barplots et boxplots\n",
    "\n",
    "Pour comprendre ce que repr√©sente chaque cluster (faible, moyen ou fort risque de cancer), on utilise :\n",
    "\n",
    "| Type de graphique        | Variables concern√©es                            | Ce qu'on observe                                                         |\n",
    "|--------------------------|--------------------------------------------------|--------------------------------------------------------------------------|\n",
    "| üì¶ Boxplot               | `√Çge`, `Poids`                                   | Rep√®re les groupes plus √¢g√©s ou corpulents                              |\n",
    "| üìä Barplot (proportions) | `Fumeur`, `Consommation_Alcool`, `Ant√©c√©dents_Familiaux` | Observe la part de patients expos√©s √† des facteurs de risque           |\n",
    "| üìä Barplot (r√©partition) | `Activit√©_Physique`                   | Compare les modalit√©s (ex : actif / non) dans chaque cluster             |\n",
    "\n",
    "\n",
    "### üìåQuestion\n",
    "\n",
    "Classer les clusters en fonction des **risques de cancers**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c75b63",
   "metadata": {},
   "source": [
    "### üå≤ 3.8 Influence des diff√©rents crit√®res\n",
    "\n",
    "Une fois les clusters identifi√©s et associ√©s √† des niveaux de risque, on peut entra√Æner un **mod√®le supervis√©** (Random Forest ici) pour d√©terminer quels crit√®res influencent le plus le classement des patients.\n",
    "\n",
    "\n",
    "#### üìò R√©sum√© ‚Äì D√©terminer l‚Äôimportance des crit√®res dans le risque de cancer (Random Forest)\n",
    "\n",
    "Pour savoir **quels crit√®res influencent le plus le classement des patients** par niveau de risque, on suit ces √©tapes :\n",
    "\n",
    "| √âtape | Description                                                                 |\n",
    "|-------|-----------------------------------------------------------------------------|\n",
    "| 1Ô∏è‚É£    | Associer chaque **cluster** (0, 1, 2) √† un **niveau de risque** (`faible`, `mod√©r√©`, `√©lev√©`) |\n",
    "| 2Ô∏è‚É£    | Ajouter cette information dans le tableau principal (`df`)                |\n",
    "| 3Ô∏è‚É£    | Utiliser le DataFrame encod√© (`X_encoded`) comme **base d‚Äôapprentissage** |\n",
    "| 4Ô∏è‚É£    | Entra√Æner un mod√®le **RandomForestClassifier** avec `Cluster` comme cible  |\n",
    "| 5Ô∏è‚É£    | Extraire l‚Äô**importance des variables** via `.feature_importances_`        |\n",
    "| 6Ô∏è‚É£    | Afficher un **histogramme horizontal** pour visualiser les crit√®res les plus d√©terminants |\n",
    "\n",
    "‚úÖ Ce processus permet d‚Äô**interpr√©ter les d√©cisions du mod√®le** et de **hi√©rarchiser les facteurs de risque** en fonction de leur contribution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f9bb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# √âtape 1 : Associer les clusters √† des niveaux de risque\n",
    "# (adapte si n√©cessaire selon ton analyse visuelle)\n",
    "cluster_risque = {\n",
    "    0: \"Mod√©r√©\",\n",
    "    1: \"Faible\",\n",
    "    2: \"√âlev√©\"\n",
    "}\n",
    "\n",
    "# √âtape 2 : Cr√©er les colonnes \"Cluster\" et \"Niveau_Risque\"\n",
    "df[\"Cluster\"] = k_labels\n",
    "df[\"Niveau_Risque\"] = df[\"Cluster\"].map(cluster_risque)\n",
    "\n",
    "# On v√©rifie que l'ajout des colonnes est effectif\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "# √âtape 3 : Utiliser les donn√©es entra√Æn√©es pr√©c√©demment \n",
    "X_features = X_encoded.copy()\n",
    "y_risque = df[\"Cluster\"]  \n",
    "\n",
    "# √âtape 4 : Entra√Æner une Random Forest pour analyser l'importance des crit√®res\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_features, y_risque)\n",
    "\n",
    "# √âtape 5 : Extraire l‚Äôimportance des variables \n",
    "importances = pd.Series(rf.feature_importances_, index=X_features.columns)\n",
    "importances.sort_values(ascending=True).plot(kind=\"barh\", figsize=(8, 6))\n",
    "\n",
    "# √âtape 6 : Les afficher sous forme d‚Äôhistogramme\n",
    "plt.title(\"Importance des crit√®res pour pr√©dire le niveau de risque (Random Forest)\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
